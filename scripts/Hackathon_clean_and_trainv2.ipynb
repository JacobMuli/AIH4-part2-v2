{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtadeScAXwjD",
        "outputId": "fd3714d1-3745-4e5c-a147-1e18249bc785"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset: /content/ndvi_filled_option_c_poly.xlsx\n",
            "Cleaning agronomic years...\n",
            "Inconsistent rows corrected: 562\n",
            "Saving cleaned CSV to: /content/ndvi_optionb_cleaned.csv\n",
            "Preparing modeling dataset...\n",
            "Modeling rows: 556\n",
            "Adding lag & rolling features per county...\n",
            "After dropping rows lacking lags: 524\n",
            "Building features and target...\n",
            "Feature matrix shape: (524, 45)\n",
            "Splitting train/test by time...\n",
            "Train rows: 495 Test rows: 29 Last year used as test: 2021\n",
            "Training RandomForest (no hyperparameter tuning by default)...\n",
            "Saving model to: /content/rf_optionb_ndvi_model_v2.joblib\n",
            "Evaluation metrics: {'mae': 1.771960523571059, 'rmse': 2.4526329433850322, 'r2': 0.5484536395639259}\n",
            "Computing SHAP summary (mean |SHAP| per feature)...\n",
            "Computing LIME summary (representative instance)...\n",
            "Saved results summary to: /content/optionb_results_summary.json\n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Clean NDVI dataset, train RandomForest model for Option B, save artifacts.\n",
        "\n",
        "Inputs:\n",
        " - /mnt/data/ndvi_filled_option_c_poly.xlsx\n",
        "\n",
        "Outputs:\n",
        " - /mnt/data/ndvi_optionb_cleaned.csv\n",
        " - /mnt/data/rf_optionb_ndvi_model_v2.joblib\n",
        " - /mnt/data/optionb_results_summary.json\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV, train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# -------------------------\n",
        "# Paths (use uploaded /mnt/data)\n",
        "# -------------------------\n",
        "INPUT_PATH = \"/content/ndvi_filled_option_c_poly.xlsx\"\n",
        "CLEAN_CSV = \"/content/ndvi_optionb_cleaned.csv\"\n",
        "MODEL_PATH = \"/content/rf_optionb_ndvi_model_v2.joblib\"\n",
        "RESULTS_JSON = \"/content/optionb_results_summary.json\"\n",
        "\n",
        "# -------------------------\n",
        "# Helper functions\n",
        "# -------------------------\n",
        "def load_data(path=INPUT_PATH):\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError(f\"Input file not found: {path}\")\n",
        "    df = pd.read_excel(path)\n",
        "    df.columns = df.columns.str.lower().str.strip()\n",
        "    return df\n",
        "\n",
        "def clean_agronomic_years(df):\n",
        "    # Ensure numeric where expected\n",
        "    for col in [\"planting_year\", \"harvest_year\", \"planting_month\", \"harvest_month\"]:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors=\"coerce\").astype(\"Int64\")\n",
        "\n",
        "    # Fix inconsistent rows where planting_year > harvest_year\n",
        "    mask = (df.get(\"planting_year\").notna()) & (df.get(\"harvest_year\").notna()) & (df[\"planting_year\"] > df[\"harvest_year\"])\n",
        "    inconsistent = df[mask].copy()\n",
        "    if not inconsistent.empty:\n",
        "        # Strategy: set harvest_year = planting_year (align season) and keep note\n",
        "        df.loc[mask, \"harvest_year\"] = df.loc[mask, \"planting_year\"]\n",
        "\n",
        "    return df, inconsistent\n",
        "\n",
        "def prepare_modeling_df(df):\n",
        "    # Filter to potato product (case-insensitive)\n",
        "    if \"product\" in df.columns:\n",
        "        mask = df[\"product\"].astype(str).str.lower().str.contains(\"potato\", na=False)\n",
        "        df = df.loc[mask].copy()\n",
        "    else:\n",
        "        # if no product column, assume dataset already filtered\n",
        "        df = df.copy()\n",
        "\n",
        "    # Keep important columns if present\n",
        "    keep_cols = [\"admin_1\",\"admin_2\",\"country\",\"harvest_year\",\"planting_year\",\"planting_month\",\"harvest_month\",\n",
        "                 \"mean_annual_ndvi\",\"area\",\"production\",\"yield\"]\n",
        "    existing = [c for c in keep_cols if c in df.columns]\n",
        "    df = df[existing].copy()\n",
        "\n",
        "    # Ensure numeric\n",
        "    if \"area\" in df.columns:\n",
        "        df[\"area\"] = pd.to_numeric(df[\"area\"], errors=\"coerce\").fillna(0.0)\n",
        "    if \"mean_annual_ndvi\" in df.columns:\n",
        "        df[\"mean_annual_ndvi\"] = pd.to_numeric(df[\"mean_annual_ndvi\"], errors=\"coerce\")\n",
        "\n",
        "    # Drop rows missing core measurement columns\n",
        "    required = []\n",
        "    if \"yield\" in df.columns:\n",
        "        required.append(\"yield\")\n",
        "    if \"mean_annual_ndvi\" in df.columns:\n",
        "        required.append(\"mean_annual_ndvi\")\n",
        "    if required:\n",
        "        df = df.dropna(subset=required).reset_index(drop=True)\n",
        "\n",
        "    # Sort for time processing\n",
        "    if \"harvest_year\" in df.columns:\n",
        "        df = df.sort_values(\"harvest_year\").reset_index(drop=True)\n",
        "    return df\n",
        "\n",
        "def add_lags_rolls_per_county(df, lags=(1,2,3)):\n",
        "    # operate per county to maintain temporal integrity\n",
        "    def _g(g):\n",
        "        g = g.sort_values(\"harvest_year\").reset_index(drop=True)\n",
        "        for lag in lags:\n",
        "            g[f\"yield_lag_{lag}\"] = g[\"yield\"].shift(lag)\n",
        "            g[f\"ndvi_lag_{lag}\"] = g[\"mean_annual_ndvi\"].shift(lag)\n",
        "        g[\"yield_roll3\"] = g[\"yield\"].rolling(3).mean().shift(1)\n",
        "        g[\"ndvi_roll3\"] = g[\"mean_annual_ndvi\"].rolling(3).mean().shift(1)\n",
        "        g[\"ndvi_change\"] = g[\"mean_annual_ndvi\"] - g[\"ndvi_lag_1\"]\n",
        "        # year index for temporal signal\n",
        "        if \"harvest_year\" in g.columns:\n",
        "            g[\"year_index\"] = g[\"harvest_year\"] - g[\"harvest_year\"].min()\n",
        "        else:\n",
        "            g[\"year_index\"] = np.arange(len(g))\n",
        "        return g\n",
        "\n",
        "    if \"admin_1\" in df.columns:\n",
        "        df = df.groupby(\"admin_1\", group_keys=False).apply(_g).reset_index(drop=True)\n",
        "    else:\n",
        "        df = _g(df)\n",
        "    return df\n",
        "\n",
        "def build_features(df, encode_county=True, max_dummies=100):\n",
        "    # numeric core\n",
        "    X_num = pd.DataFrame({\n",
        "        \"mean_annual_ndvi\": df[\"mean_annual_ndvi\"].astype(float),\n",
        "        \"area\": df.get(\"area\", pd.Series(0.0)).astype(float),\n",
        "        \"planting_month\": df.get(\"planting_month\", pd.Series(1)).fillna(1).astype(int),\n",
        "        \"year_index\": df.get(\"year_index\", pd.Series(0)).astype(int),\n",
        "        \"yield_lag_1\": df.get(\"yield_lag_1\"),\n",
        "        \"yield_lag_2\": df.get(\"yield_lag_2\"),\n",
        "        \"yield_lag_3\": df.get(\"yield_lag_3\"),\n",
        "        \"yield_roll3\": df.get(\"yield_roll3\"),\n",
        "        \"ndvi_lag_1\": df.get(\"ndvi_lag_1\"),\n",
        "        \"ndvi_lag_2\": df.get(\"ndvi_lag_2\"),\n",
        "        \"ndvi_lag_3\": df.get(\"ndvi_lag_3\"),\n",
        "        \"ndvi_roll3\": df.get(\"ndvi_roll3\"),\n",
        "        \"ndvi_change\": df.get(\"ndvi_change\")\n",
        "    })\n",
        "\n",
        "    X_num = X_num.astype(float).fillna(0.0)\n",
        "\n",
        "    # county dummies\n",
        "    if encode_county and \"admin_1\" in df.columns and df[\"admin_1\"].nunique() <= max_dummies:\n",
        "        dummies = pd.get_dummies(df[\"admin_1\"].fillna(\"unknown\"), prefix=\"adm1\")\n",
        "        X = pd.concat([X_num.reset_index(drop=True), dummies.reset_index(drop=True)], axis=1)\n",
        "    else:\n",
        "        X = X_num\n",
        "\n",
        "    y = df[\"yield\"].astype(float).values\n",
        "    return X, y\n",
        "\n",
        "def time_train_test_split(df, X, y, time_col=\"harvest_year\"):\n",
        "    # prefer time-based split: last harvest year -> test\n",
        "    if time_col in df.columns:\n",
        "        years = pd.to_numeric(df[time_col], errors=\"coerce\").astype(\"Int64\")\n",
        "        last_year = int(years.max())\n",
        "        train_mask = years < last_year\n",
        "        test_mask = years == last_year\n",
        "\n",
        "        # If too small, fall back to random split\n",
        "        if train_mask.sum() < 10 or test_mask.sum() < 5:\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "            last_year = int(years.max())\n",
        "        else:\n",
        "            X_train = X.loc[train_mask]\n",
        "            X_test = X.loc[test_mask]\n",
        "            y_train = y[train_mask.values]\n",
        "            y_test = y[test_mask.values]\n",
        "    else:\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "        last_year = None\n",
        "    return X_train, X_test, y_train, y_test, last_year\n",
        "\n",
        "def train_rf(X_train, y_train, do_tune=False):\n",
        "    rf = RandomForestRegressor(n_estimators=300, random_state=42, n_jobs=-1)\n",
        "    if not do_tune:\n",
        "        rf.fit(X_train, y_train)\n",
        "        return rf, None\n",
        "    # tuning with TimeSeriesSplit\n",
        "    param_dist = {\n",
        "        \"n_estimators\": [200, 300, 500],\n",
        "        \"max_depth\": [5, 10, 15, None],\n",
        "        \"min_samples_split\": [2, 5, 10],\n",
        "        \"min_samples_leaf\": [1, 2, 4]\n",
        "    }\n",
        "    tscv = TimeSeriesSplit(n_splits=5)\n",
        "    rnd = RandomizedSearchCV(rf, param_distributions=param_dist, n_iter=20, cv=tscv, scoring=\"neg_mean_absolute_error\", n_jobs=-1, random_state=42)\n",
        "    rnd.fit(X_train, y_train)\n",
        "    return rnd.best_estimator_, rnd\n",
        "\n",
        "def evaluate(y_test, y_pred):\n",
        "    if len(y_test) == 0:\n",
        "        return {\"mae\": None, \"rmse\": None, \"r2\": None}\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = float(np.sqrt(mse))\n",
        "    r2 = float(r2_score(y_test, y_pred))\n",
        "    return {\"mae\": float(mae), \"rmse\": rmse, \"r2\": r2}\n",
        "\n",
        "def compute_shap_summary(model, X, top_k=10):\n",
        "    try:\n",
        "        import shap\n",
        "        explainer = shap.TreeExplainer(model)\n",
        "        # sample for speed\n",
        "        sample_n = min(500, X.shape[0])\n",
        "        X_sample = X.sample(sample_n, random_state=42)\n",
        "        shap_values = explainer.shap_values(X_sample)\n",
        "        mean_abs = np.abs(shap_values).mean(axis=0)\n",
        "        order_idx = np.argsort(-mean_abs)\n",
        "        features = X_sample.columns[order_idx][:top_k].tolist()\n",
        "        scores = mean_abs[order_idx][:top_k].tolist()\n",
        "        shap_summary = [{\"feature\": f, \"mean_abs_shap\": float(s)} for f,s in zip(features, scores)]\n",
        "        return shap_summary\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "def compute_lime_summary(model, X_train, X_full, idx=None, num_features=8):\n",
        "    try:\n",
        "        from lime.lime_tabular import LimeTabularExplainer\n",
        "        # pick representative instance\n",
        "        if idx is None:\n",
        "            idx = int(len(X_full) // 2)\n",
        "        # ensure training sample small enough for LIME\n",
        "        train_sample = X_train.sample(min(1000, X_train.shape[0]), random_state=1).values\n",
        "        explainer = LimeTabularExplainer(train_sample, feature_names=X_train.columns.tolist(), mode='regression')\n",
        "        exp = explainer.explain_instance(X_full.iloc[idx].values, model.predict, num_features=num_features)\n",
        "        lime_list = exp.as_list()\n",
        "        # split pos/neg\n",
        "        pos = [t for t in lime_list if t[1] > 0]\n",
        "        neg = [t for t in lime_list if t[1] < 0]\n",
        "        lime_summary = {\n",
        "            \"instance_index\": int(idx),\n",
        "            \"top_positive\": pos[:5],\n",
        "            \"top_negative\": neg[:5]\n",
        "        }\n",
        "        return lime_summary\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "# -------------------------\n",
        "# Recursive forecasting function (per-county) that updates lag features\n",
        "# -------------------------\n",
        "def recursive_forecast_by_county(agg_df, rf_model, features_list, years_ahead=1, area_override_val=None):\n",
        "    \"\"\"\n",
        "    agg_df: aggregated per year DataFrame for a county with columns:\n",
        "            ['harvest_year','area','production','mean_annual_ndvi','yield','admin_1']\n",
        "    rf_model: trained model\n",
        "    features_list: ORDERED list of features model expects\n",
        "    years_ahead: int\n",
        "    area_override_val: if provided, use same area for predictions\n",
        "    \"\"\"\n",
        "    hist = agg_df.sort_values(\"harvest_year\").reset_index(drop=True).copy()\n",
        "    preds = []\n",
        "    for step in range(years_ahead):\n",
        "        last = hist.iloc[-1].copy()\n",
        "        # compute lags\n",
        "        for lag in [1,2,3]:\n",
        "            if len(hist) >= lag:\n",
        "                last[f\"yield_lag_{lag}\"] = hist[\"yield\"].iloc[-lag]\n",
        "                last[f\"ndvi_lag_{lag}\"] = hist[\"mean_annual_ndvi\"].iloc[-lag]\n",
        "            else:\n",
        "                last[f\"yield_lag_{lag}\"] = hist[\"yield\"].iloc[-1]\n",
        "                last[f\"ndvi_lag_{lag}\"] = hist[\"mean_annual_ndvi\"].iloc[-1]\n",
        "        last[\"yield_roll3\"] = hist[\"yield\"].iloc[-3:].mean() if len(hist) >= 3 else hist[\"yield\"].mean()\n",
        "        last[\"ndvi_roll3\"] = hist[\"mean_annual_ndvi\"].iloc[-3:].mean() if len(hist) >= 3 else hist[\"mean_annual_ndvi\"].mean()\n",
        "        last[\"ndvi_change\"] = last[\"mean_annual_ndvi\"] - last.get(\"ndvi_lag_1\", last[\"mean_annual_ndvi\"])\n",
        "        last[\"year_index\"] = last[\"harvest_year\"] - agg_df[\"harvest_year\"].min() + (step + 1)\n",
        "        # build feature vector in required order\n",
        "        xrow = []\n",
        "        for feat in features_list:\n",
        "            if feat in last:\n",
        "                xrow.append(last[feat])\n",
        "            else:\n",
        "                if feat.startswith(\"adm1_\"):\n",
        "                    xrow.append(1.0 if feat == f\"adm1_{last['admin_1']}\" else 0.0)\n",
        "                else:\n",
        "                    xrow.append(0.0)\n",
        "        xarr = np.array([xrow], dtype=float)\n",
        "        pred_y = float(rf_model.predict(xarr)[0])\n",
        "        area_use = area_override_val if area_override_val is not None else last[\"area\"]\n",
        "        pred_prod = pred_y * area_use\n",
        "        next_year = int(last[\"harvest_year\"]) + 1\n",
        "        preds.append({\"harvest_year\": next_year, \"predicted_yield\": float(pred_y), \"predicted_production\": float(pred_prod)})\n",
        "        new_hist = {\n",
        "            \"harvest_year\": next_year,\n",
        "            \"area\": area_use,\n",
        "            \"production\": pred_prod,\n",
        "            \"mean_annual_ndvi\": last[\"mean_annual_ndvi\"],  # keeping NDVI stable (optionally forecast NDVI separately)\n",
        "            \"yield\": pred_y,\n",
        "            \"admin_1\": last[\"admin_1\"]\n",
        "        }\n",
        "        hist = pd.concat([hist, pd.DataFrame([new_hist])], ignore_index=True)\n",
        "    return pd.DataFrame(preds)\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Main\n",
        "# -------------------------\n",
        "def main():\n",
        "    print(\"Loading dataset:\", INPUT_PATH)\n",
        "    df = load_data(INPUT_PATH)\n",
        "\n",
        "    print(\"Cleaning agronomic years...\")\n",
        "    df_clean, inconsistent_rows = clean_agronomic_years(df)\n",
        "    print(\"Inconsistent rows corrected:\", int(inconsistent_rows.shape[0]))\n",
        "\n",
        "    print(\"Saving cleaned CSV to:\", CLEAN_CSV)\n",
        "    df_clean.to_csv(CLEAN_CSV, index=False)\n",
        "\n",
        "    print(\"Preparing modeling dataset...\")\n",
        "    mdl = prepare_modeling_df(df_clean)\n",
        "    if mdl.shape[0] == 0:\n",
        "        raise ValueError(\"No rows available for modeling after filtering. Check dataset columns and product filtering.\")\n",
        "    print(\"Modeling rows:\", int(mdl.shape[0]))\n",
        "\n",
        "    print(\"Adding lag & rolling features per county...\")\n",
        "    mdl = add_lags_rolls_per_county(mdl)\n",
        "\n",
        "    # Drop rows missing the essential lag features (first few years per county)\n",
        "    required_lags = [\"yield_lag_1\", \"ndvi_lag_1\"]\n",
        "    mdl_model = mdl.dropna(subset=required_lags).reset_index(drop=True)\n",
        "    print(\"After dropping rows lacking lags:\", int(mdl_model.shape[0]))\n",
        "\n",
        "    print(\"Building features and target...\")\n",
        "    X, y = build_features(mdl_model, encode_county=True, max_dummies=150)\n",
        "    print(\"Feature matrix shape:\", X.shape)\n",
        "\n",
        "    print(\"Splitting train/test by time...\")\n",
        "    X_train, X_test, y_train, y_test, last_year = time_train_test_split(mdl_model, X, y)\n",
        "    print(\"Train rows:\", int(X_train.shape[0]), \"Test rows:\", int(X_test.shape[0]), \"Last year used as test:\", last_year)\n",
        "\n",
        "    # Train model\n",
        "    print(\"Training RandomForest (no hyperparameter tuning by default)...\")\n",
        "    rf, rnd = train_rf(X_train, y_train, do_tune=False)\n",
        "\n",
        "    # Save model\n",
        "    print(\"Saving model to:\", MODEL_PATH)\n",
        "    joblib.dump(rf, MODEL_PATH)\n",
        "\n",
        "    # Evaluate\n",
        "    y_pred = rf.predict(X_test) if X_test.shape[0] > 0 else np.array([])\n",
        "    results = evaluate(y_test, y_pred)\n",
        "    print(\"Evaluation metrics:\", results)\n",
        "\n",
        "    # Compute SHAP summary (lightweight)\n",
        "    print(\"Computing SHAP summary (mean |SHAP| per feature)...\")\n",
        "    shap_summary = compute_shap_summary(rf, X)\n",
        "\n",
        "    # Compute LIME summary for representative instance\n",
        "    print(\"Computing LIME summary (representative instance)...\")\n",
        "    lime_summary = compute_lime_summary(rf, X_train, X)\n",
        "\n",
        "    # Save final summary JSON\n",
        "    summary = {\n",
        "        \"input_path\": INPUT_PATH,\n",
        "        \"clean_csv\": CLEAN_CSV,\n",
        "        \"model_path\": MODEL_PATH,\n",
        "        \"n_rows_original\": int(pd.read_excel(INPUT_PATH).shape[0]),\n",
        "        \"n_rows_cleaned\": int(df_clean.shape[0]),\n",
        "        \"n_rows_modeling\": int(mdl_model.shape[0]),\n",
        "        \"unique_counties\": int(mdl_model[\"admin_1\"].nunique()) if \"admin_1\" in mdl_model.columns else 0,\n",
        "        \"last_harvest_year_used_as_test\": int(last_year) if last_year is not None else None,\n",
        "        \"train_rows\": int(X_train.shape[0]),\n",
        "        \"test_rows\": int(X_test.shape[0]),\n",
        "        \"evaluation\": results,\n",
        "        \"features\": X.columns.tolist(),\n",
        "        \"shap_summary\": shap_summary,\n",
        "        \"lime_summary\": lime_summary\n",
        "    }\n",
        "\n",
        "    with open(RESULTS_JSON, \"w\") as f:\n",
        "        json.dump(summary, f, indent=2, default=lambda o: (o.__name__ if callable(o) else str(o)))\n",
        "    print(\"Saved results summary to:\", RESULTS_JSON)\n",
        "    print(\"Done.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}